# llm-inference-solutions
A collection of all available inference solutions for the LLMs

| Name  | Org  | Description | 
| ------------- |:-------------:| -------------:|
|   [vllm](https://github.com/vllm-project/vllm)    |  UC Berkeley    |  A high-throughput and memory-efficient inference and serving engine for LLMs
| [Text-Generation-Inference](https://github.com/huggingface/text-generation-inference)      | HugginfaceðŸ¤—     |Large Language Model Text Generation Inference
| [llm-engine](https://github.com/scaleapi/llm-engine)      | ScaleAI     |Scale LLM Engine public repository
